# ğŸ—ï¸ Docker Services Architecture - NoCode Backend

## ğŸ¯ Vue d'ensemble

L'architecture NoCode Backend repose sur **5 services Docker** qui collaborent pour fournir une plateforme complÃ¨te de crÃ©ation d'API dynamique.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Web     â”‚  â”‚   Redis     â”‚  â”‚   Celery    â”‚
â”‚  (Django +  â”‚  â”‚   (Cache +  â”‚  â”‚   (Worker)  â”‚
â”‚  Gunicorn)  â”‚â”€â”€â”‚   Broker)   â”‚â”€â”€â”‚             â”‚
â”‚   Port 8000 â”‚  â”‚   Port 6379 â”‚  â”‚   No Port   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                â”‚                â”‚
       â”‚                â”‚                â”‚
       â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚  â”‚  Celery Beat    â”‚
â”‚   (Base de      â”‚  â”‚   (Scheduler)   â”‚
â”‚    donnÃ©es)     â”‚  â”‚                 â”‚
â”‚    Port 5432    â”‚  â”‚   No Port       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Services DÃ©taillÃ©s

### 1. **Web Service** - Django + Gunicorn

**RÃ´le principal :** Serveur d'application Django

**Configuration :**
```yaml
web:
  build: .
  command: gunicorn config.wsgi:application --bind 0.0.0.0:8000 --workers 3
  environment:
    - DEBUG=False
    - DATABASE_URL=postgresql://user:pass@db:5432/nocode
    - REDIS_URL=redis://redis:6379/0
    - CELERY_BROKER_URL=redis://redis:6379/0
```

**ResponsabilitÃ©s :**
- **API REST** : GÃ¨re tous les endpoints HTTP (80+ endpoints)
- **Authentification JWT** : Tokens et permissions
- **CRUD Dynamique** : CrÃ©ation/mise Ã  jour des tables
- **Validation** : SchÃ©mas et contraintes de donnÃ©es
- **Middleware** : CORS, sÃ©curitÃ©, logging
- **Admin Django** : Interface d'administration

**Processus internes :**
```
Request â†’ Gunicorn â†’ Django â†’ Response
          â†“
    API Calls â†’ Django â†’ Database/Redis
          â†“
    Static Files â†’ Django Static Files
```

**Ports exposÃ©s :**
- `8000` : API REST + Admin Django
- **Aucun port reverse proxy** (direct Gunicorn)

**Volumes montÃ©s :**
- `./static` : Fichiers statiques Django
- `./media` : Fichiers uploadÃ©s
- `./logs` : Logs d'application

---

### 2. **Database Service** - PostgreSQL

**RÃ´le principal :** Base de donnÃ©es principale

**Configuration :**
```yaml
db:
  image: postgres:15-alpine
  environment:
    - POSTGRES_DB=nocode_backend
    - POSTGRES_USER=nocode_user
    - POSTGRES_PASSWORD=secure_password
  volumes:
    - postgres_data:/var/lib/postgresql/data
```

**ResponsabilitÃ©s :**
- **DonnÃ©es utilisateur** : Comptes, organisations, permissions
- **Projets NoCode** : SchÃ©mas, configurations
- **Tables dynamiques** : DonnÃ©es utilisateur avec prÃ©fixes `project_{id}_`
- **Sessions** : Stockage des sessions Django
- **TÃ¢ches Celery** : Queue et rÃ©sultats des tÃ¢ches

**Structure des tables :**
```sql
-- Tables systÃ¨me
users, organizations, projects, data_schemas

-- Tables dynamiques (crÃ©Ã©es automatiquement)
project_1_clients, project_1_produits
project_2_orders, project_2_customers
```

---

### 3. **Redis Service** - Cache + Message Broker

**RÃ´le principal :** Cache et broker pour Celery

**Configuration :**
```yaml
redis:
  image: redis:7-alpine
  command: redis-server --requirepass redis_password
  volumes:
    - redis_data:/data
```

**ResponsabilitÃ©s :**
- **Cache Django** : Sessions, fragments de vue
- **Cache API** : RÃ©ponses frÃ©quentes, mÃ©tadonnÃ©es
- **Message Broker** : Queue pour Celery
- **Real-time** : WebSocket, notifications
- **Rate Limiting** : Limitation de dÃ©bit API

**Patterns Redis utilisÃ©s :**
```
cache:project:{id} â†’ MÃ©tadonnÃ©es projet
cache:schema:{table} â†’ Configuration table
celery:task:{id} â†’ RÃ©sultats tÃ¢ches
session:{key} â†’ Sessions utilisateur
```

---

### 4. **Celery Service** - Worker Asynchrone

**RÃ´le principal :** ExÃ©cution des tÃ¢ches en arriÃ¨re-plan

**Configuration :**
```yaml
celery:
  build: .
  command: celery -A config worker -l info --concurrency=4
  environment:
    - DATABASE_URL=postgresql://user:pass@db:5432/nocode
    - CELERY_BROKER_URL=redis://redis:6379/0
```

**ResponsabilitÃ©s :**
- **GÃ©nÃ©ration d'applications** : CrÃ©ation des modÃ¨les Django
- **DÃ©ploiement Runtime** : Mise en production des apps
- **Workflows Automation** : ExÃ©cution des graphes
- **Analytics Processing** : AgrÃ©gation des mÃ©triques
- **Email Notifications** : Envoi d'emails asynchrones
- **File Processing** : Upload, conversion, export

**Types de tÃ¢ches :**
```python
# TÃ¢ches de gÃ©nÃ©ration
generate_application(project_id)
deploy_application(app_id)

# TÃ¢ches automation
execute_workflow(workflow_id, data)
process_integration(integration_id)

# TÃ¢ches analytics
process_events_batch(event_data)
generate_analytics_report(project_id)
```

---

### 5. **Celery Beat Service** - Scheduler

**RÃ´le principal :** Planification des tÃ¢ches rÃ©currentes

**Configuration :**
```yaml
celery-beat:
  build: .
  command: celery -A config beat -l info --scheduler django_celery_beat.schedulers:DatabaseScheduler
  environment:
    - DATABASE_URL=postgresql://user:pass@db:5432/nocode
    - CELERY_BROKER_URL=redis://redis:6379/0
```

**ResponsabilitÃ©s :**
- **TÃ¢ches planifiÃ©es** : Rapports quotidiens/hebdomadaires
- **Maintenance** : Nettoyage des logs, cache
- **Analytics** : AgrÃ©gations pÃ©riodiques
- **Notifications** : Rappels, alertes
- **Backup** : Sauvegardes automatiques

**Schedule types :**
```python
# TÃ¢ches quotidiennes
daily_analytics_report â†’ 00:00 UTC
cleanup_old_sessions â†’ 02:00 UTC

# TÃ¢ches hebdomadaires
weekly_usage_report â†’ Lundi 08:00 UTC
database_maintenance â†’ Dimanche 03:00 UTC

# TÃ¢ches mensuelles
monthly_billing_report â†’ 1er du mois
```

---

### 2. **PostgreSQL** - Base de donnÃ©es principale

**RÃ´le principal :** Stockage persistant des donnÃ©es

**Configuration :**
```yaml
db:
  image: postgres:15-alpine
  environment:
    POSTGRES_DB: nocode_prod
    POSTGRES_USER: nocode_user
    POSTGRES_PASSWORD: secure_password
  volumes:
    - postgres_data:/var/lib/postgresql/data
```

**Structure des donnÃ©es :**
```sql
-- Tables Django (fixes)
django_migrations
auth_user
foundation_organization
studio_dataschema
studio_fieldschema

-- Tables dynamiques (crÃ©Ã©es Ã  l'exÃ©cution)
project_{uuid}_products
project_{uuid}_customers
project_{uuid}_tasks
```

**ResponsabilitÃ©s :**
- **DonnÃ©es utilisateur** : Authentification, organisations
- **MÃ©tadonnÃ©es** : SchÃ©mas de tables, dÃ©finitions de champs
- **DonnÃ©es dynamiques** : Tables crÃ©Ã©es par les utilisateurs
- **Transactions** : ACID compliance pour la cohÃ©rence
- **Persistance** : Sauvegarde et rÃ©cupÃ©ration

**Performance :**
- **Indexation automatique** sur les clÃ©s primaires
- **Connections pooling** via Django
- **Health checks** pour monitoring

---

### 3. **Redis** - Cache et Message Broker

**RÃ´le principal :** Cache et file d'attente pour tÃ¢ches asynchrones

**Configuration :**
```yaml
redis:
  image: redis:7-alpine
  command: redis-server --requirepass secure_password
  volumes:
    - redis_data:/data
```

**Utilisations multiples :**

#### ğŸ—„ï¸ **Cache Django**
```python
# Cache des schÃ©mas frÃ©quemment accÃ©dÃ©s
CACHE_KEY = "project_{uuid}_schema"
TTL = 3600  # 1 heure

# Cache des permissions utilisateur
CACHE_KEY = "user_{user_id}_permissions"
TTL = 1800  # 30 minutes
```

#### ğŸ“¨ **Celery Message Broker**
```python
# File d'attente des tÃ¢ches
CELERY_BROKER_URL = "redis://redis:6379/0"
CELERY_RESULT_BACKEND = "redis://redis:6379/0"

# Types de tÃ¢ches
- backup_database
- generate_report
- send_notifications
- cleanup_temp_files
```

#### ğŸ”„ **Session Storage**
```python
# Sessions utilisateur (optionnel)
SESSION_ENGINE = "django.contrib.sessions.backends.cache"
SESSION_CACHE_ALIAS = "default"
```

---

### 4. **Celery Worker** - TÃ¢ches asynchrones

**RÃ´le principal :** ExÃ©cution des tÃ¢ches en arriÃ¨re-plan

**Configuration :**
```yaml
celery:
  image: your-dockerhub-username/nocode-backend:latest
  command: celery -A config worker -l info --concurrency=4
  environment:
    - DATABASE_URL=postgresql://user:pass@db:5432/nocode
    - CELERY_BROKER_URL=redis://redis:6379/0
```

**Types de tÃ¢ches :**

#### ğŸ“Š **TÃ¢ches de traitement**
```python
@shared_task
def generate_project_report(project_id, format="pdf"):
    """GÃ©nÃ©rer un rapport de projet"""
    # RÃ©cupÃ©rer les donnÃ©es
    # GÃ©nÃ©rer le PDF/Excel
    # Envoyer par email
    pass

@shared_task
def backup_project_data(project_id):
    """Sauvegarder les donnÃ©es d'un projet"""
    # Exporter toutes les tables
    # Compresser l'archive
    # Stocker sur S3/FTP
    pass
```

#### ğŸ”” **TÃ¢ches de notification**
```python
@shared_task
def send_welcome_email(user_id):
    """Envoyer email de bienvenue"""
    pass

@shared_task
def notify_project_changes(project_id, changes):
    """Notifier les modifications"""
    pass
```

#### ğŸ§¹ **TÃ¢ches de maintenance**
```python
@shared_task
def cleanup_old_sessions():
    """Nettoyer les anciennes sessions"""
    pass

@shared_task
def update_project_statistics():
    """Mettre Ã  jour les statistiques"""
    pass
```

---

### 5. **Celery Beat** - Planificateur de tÃ¢ches

**RÃ´le principal :** ExÃ©cution planifiÃ©e des tÃ¢ches rÃ©currentes

**Configuration :**
```yaml
celery-beat:
  image: your-dockerhub-username/nocode-backend:latest
  command: celery -A config beat -l info --scheduler django_celery_beat.schedulers:DatabaseScheduler
```

**TÃ¢ches planifiÃ©es :**

```python
# TÃ¢ches quotidiennes
0 2 * * *   â†’ backup_all_projects()      # 2h du matin
0 3 * * *   â†’ cleanup_temp_files()       # 3h du matin
0 4 * * *   â†’ update_analytics()         # 4h du matin

# TÃ¢ches hebdomadaires  
0 6 * * 1   â†’ generate_weekly_report()   # Lundi 6h
0 7 * * 1   â†’ system_health_check()      # Lundi 7h

# TÃ¢ches mensuelles
0 8 1 * *   â†’ monthly_usage_report()     # 1er du mois 8h
```

---

## ğŸ”„ Communication Entre Services

### Flow de RequÃªte API

```
1. Client â†’ Nginx (Port 80/443)
2. Nginx â†’ Web Service (Port 8000)
3. Web â†’ Redis (Cache/Permissions)
4. Web â†’ PostgreSQL (DonnÃ©es)
5. Web â†’ Redis (Celery Queue) [si tÃ¢che async]
6. Celery Worker â†’ Redis (prend tÃ¢che)
7. Celery Worker â†’ PostgreSQL (exÃ©cute tÃ¢che)
```

### Flow de TÃ¢che Asynchrone

```
1. API POST /api/v1/automation/tasks/
2. Web Service â†’ Redis Queue (task_data)
3. Celery Worker â†’ Redis (prend tÃ¢che)
4. Celery Worker â†’ PostgreSQL (traitement)
5. Celery Worker â†’ Redis (resultat)
6. Client â†’ API GET /api/v1/automation/tasks/{id}/status/
```

### Flow de Cache

```
1. Request API â†’ Web Service
2. Web Service â†’ Redis (vÃ©rifie cache)
3. Si HIT: Retourne donnÃ©es cachees
4. Si MISS: 
   - Web Service â†’ PostgreSQL
   - PostgreSQL â†’ Web Service  
   - Web Service â†’ Redis (stocke cache)
   - Web Service â†’ Client
```

---

## ğŸ“ Volumes et Persistance

### Volumes PostgreSQL
```yaml
volumes:
  postgres_data:
    driver: local
    # Contient: 
    # - DonnÃ©es utilisateur
    # - Tables dynamiques
    # - MÃ©tadonnÃ©es Django
```

### Volumes Redis
```yaml
volumes:
  redis_data:
    driver: local
    # Contient:
    # - Cache persistant
    # - Files d'attente Celery
    # - Sessions utilisateur
```

### Volumes Application
```yaml
volumes:
  static_files:
    # Fichiers statiques collectÃ©s
  media_files:
    # Uploads utilisateurs
  logs:
    # Logs applicatifs
```

---

## ğŸŒ RÃ©seaux Docker

### Architecture rÃ©seau
```yaml
networks:
  nocode_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
```

### Communication inter-services
```bash
# RÃ©solution DNS automatique
web â†’ db:5432          # PostgreSQL
web â†’ redis:6379       # Redis
celery â†’ db:5432       # PostgreSQL  
celery â†’ redis:6379    # Redis
nginx â†’ web:8000       # Django
```

### SÃ©curitÃ© rÃ©seau
```yaml
# Seul Nginx expose des ports publics
ports:
  - "80:80"     # Nginx HTTP
  - "443:443"   # Nginx HTTPS
  
# Services internes uniquement
# db:5432, redis:6379, web:8000 non exposÃ©s
```

---

## ğŸ“Š Monitoring et Health Checks

### Health Checks par service

#### Web Service
```yaml
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/foundation/health/"]
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 40s
```

#### PostgreSQL
```yaml
healthcheck:
  test: ["CMD-SHELL", "pg_isready -U nocode_user"]
  interval: 10s
  timeout: 5s
  retries: 5
```

#### Redis
```yaml
healthcheck:
  test: ["CMD", "redis-cli", "ping"]
  interval: 10s
  timeout: 5s
  retries: 3
```

### Metrics collectÃ©es

#### Application Metrics
```python
# API Metrics
- Requests par minute
- Temps de rÃ©ponse moyen
- Taux d'erreur 4xx/5xx
- Utilisateurs actifs

# Business Metrics  
- Nombre de projets
- Tables crÃ©Ã©es par jour
- Volume de donnÃ©es stockÃ©es
- TÃ¢ches Celery exÃ©cutÃ©es
```

#### Infrastructure Metrics
```bash
# Docker Stats
CPU Usage par conteneur
Memory Usage par conteneur
Network I/O
Disk I/O

# PostgreSQL
Connections actives
Query performance
Database size
Index usage

# Redis
Memory usage
Keyspace hits/misses
Connected clients
Queue length
```

---

## ğŸš¨ Gestion des Erreurs

### StratÃ©gies de retry

#### Celery Tasks
```python
@app.task(bind=True, max_retries=3)
def unreliable_task(self, data):
    try:
        # Logique mÃ©tier
        pass
    except Exception as exc:
        # Retry avec backoff exponentiel
        raise self.retry(exc=exc, countdown=60 * (2 ** self.request.retries))
```

#### Database Connections
```python
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'OPTIONS': {
            'connect_timeout': 10,
            'MAX_CONNS': 20,
            'RETRY_ATTEMPTS': 3
        }
    }
}
```

### Logging Strategy

#### Structure des logs
```python
LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'json': {
            'format': '{"level": "%(levelname)s", "time": "%(asctime)s", "service": "web", "message": "%(message)s"}'
        }
    },
    'handlers': {
        'console': {
            'class': 'logging.StreamHandler',
            'formatter': 'json'
        }
    },
    'root': {
        'level': 'INFO',
        'handlers': ['console']
    }
}
```

#### Logs par service
```bash
# Web Service logs
docker-compose logs web | grep "ERROR\|WARNING"

# Database logs  
docker-compose logs db | grep "ERROR\|FATAL"

# Celery task logs
docker-compose logs celery | grep "FAILED\|RETRY"
```

---

## ğŸ”§ Optimisations et Performance

### Scaling Horizontal

#### Web Service Scaling
```yaml
# docker-compose.prod.yml
services:
  web:
    deploy:
      replicas: 3  # 3 instances web
    load_balancing: nginx
  
  celery:
    deploy:
      replicas: 2  # 2 workers
```

#### Database Scaling
```yaml
# Read replicas pour lectures
db_read_replica:
  image: postgres:15-alpine
  environment:
    POSTGRES_MASTER_SERVICE: db
  
# Connection pooling
pgbouncer:
  image: pgbouncer/pgbouncer
  environment:
    DATABASES_HOST: db
    DATABASES_PORT: 5432
```

### Performance Tuning

#### Django Settings
```python
# Database optimization
DATABASES = {
    'default': {
        'CONN_MAX_AGE': 60,
        'OPTIONS': {
            'MAX_CONNS': 20,
            'application_name': 'nocode_backend'
        }
    }
}

# Cache configuration
CACHES = {
    'default': {
        'BACKEND': 'django_redis.cache.RedisCache',
        'LOCATION': 'redis://redis:6379/1',
        'OPTIONS': {
            'CLIENT_CLASS': 'django_redis.client.DefaultClient',
            'SOCKET_CONNECT_TIMEOUT': 5,
            'SOCKET_TIMEOUT': 5,
            'MAX_CONNECTIONS': 50
        }
    }
}

# Celery optimization
CELERY_WORKER_CONCURRENCY = 4
CELERY_WORKER_PREFETCH_MULTIPLIER = 1
CELERY_TASK_ACKS_LATE = True
```

#### Resource Limits
```yaml
services:
  web:
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'
  
  db:
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'
```

---

## ğŸ”„ Cycle de Vie des Services

### DÃ©marrage (Startup Order)
```
1. db (PostgreSQL) â†’ Health check ready
2. redis â†’ Health check ready  
3. web â†’ Attend db + redis + migrations
4. celery â†’ Attend db + redis
5. celery-beat â†’ Attend db + redis
6. nginx â†’ Attend web ready
```

### ArrÃªt (Shutdown Order)
```
1. nginx â†’ Stop nouvelles requÃªtes
2. web â†’ Finish requÃªtes en cours
3. celery-beat â†’ Stop planification
4. celery â†’ Finish tÃ¢ches en cours
5. redis â†’ Flush et stop
6. db â†’ Flush et stop
```

### Mises Ã  jour (Rolling Update)
```
1. Pull nouvelle image
2. Update service par service
3. Health check validation
4. Passer au service suivant
5. Rollback si erreur
```

---

## ğŸ“ˆ CapacitÃ© et Limites

### Limites techniques

#### Par projet
- **Tables maximum** : 100 tables
- **Champs par table** : 50 champs
- **Enregistrements** : IllimitÃ© (performance dÃ©pend de la DB)
- **Stockage** : LimitÃ© par le disque

#### Par instance
- **Utilisateurs simultanÃ©s** : 1000 (avec 3 workers)
- **RequÃªtes/second** : ~500 (dÃ©pend de la complexitÃ©)
- **TÃ¢ches Celery** : 100 concurrentes
- **Cache Redis** : 1GB (configurable)

### Scaling recommendations

#### Petites installations (< 100 users)
```yaml
web: 1 worker (1 CPU, 512MB RAM)
celery: 1 worker (1 CPU, 512MB RAM)  
db: 1 CPU, 1GB RAM
redis: 512MB RAM
```

#### Moyennes installations (100-1000 users)
```yaml
web: 3 workers (2 CPU, 2GB RAM)
celery: 2 workers (2 CPU, 2GB RAM)
db: 2 CPU, 4GB RAM
redis: 1GB RAM
```

#### Grandes installations (> 1000 users)
```yaml
web: 5+ workers (4+ CPU, 4GB+ RAM)
celery: 3+ workers (4+ CPU, 4GB+ RAM)
db: Cluster PostgreSQL
redis: Cluster Redis
nginx: Load balancer
```

---

*Documentation de l'architecture Docker - Version 1.0*
